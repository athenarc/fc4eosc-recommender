{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zbMATH Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for training the community recommendation engine of zbMATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import Deduplicate, MinItemsPerUser, MinUsersPerItem\n",
    "from recpack.pipelines import PipelineBuilder, HyperoptInfo\n",
    "from recpack.pipelines.registries import ALGORITHM_REGISTRY\n",
    "from recpack.scenarios import WeakGeneralization\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "# models\n",
    "from recommenders.ease import myEASE\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"communities/zbmath/interaction.csv\")\n",
    "# df = pd.read_csv(\"communities/dariah/interaction.csv\")\n",
    "# df = pd.read_csv(\"communities/digital-humanities/interaction.csv\")\n",
    "df = pd.read_csv(\"communities/transport-research/interaction.csv\")\n",
    "\n",
    "# define preprocessor\n",
    "df_pp = DataFramePreprocessor(\"item_id\", \"user_id\")\n",
    "\n",
    "# define filters\n",
    "deduplicate = Deduplicate(\"item_id\", \"user_id\")\n",
    "min_users_per_item_filter = MinUsersPerItem(25, \"item_id\", \"user_id\")\n",
    "min_items_per_user_filter = MinItemsPerUser(25, \"item_id\", \"user_id\")\n",
    "\n",
    "# add filters to pre-processor\n",
    "df_pp.add_filter(deduplicate)\n",
    "df_pp.add_filter(min_users_per_item_filter)\n",
    "df_pp.add_filter(min_items_per_user_filter)\n",
    "\n",
    "# create interaction matrix object\n",
    "im = df_pp.process(df)\n",
    "\n",
    "# save sparse matrix\n",
    "# save_npz(\"communities/zbmath/csr\", im.binary_values)\n",
    "# save_npz(\"communities/dariah/csr\", im.binary_values)\n",
    "# save_npz(\"communities/digital-humanities/csr\", im.binary_values)\n",
    "save_npz(\"communities/transport-research/csr\", im.binary_values)\n",
    "\n",
    "# save mappings\n",
    "# df_pp.item_id_mapping.to_parquet(\"communities/zbmath/items_mapping.parquet\", index=False)\n",
    "# df_pp.user_id_mapping.to_parquet(\"communities/zbmath/users_mapping.parquet\", index=False)\n",
    "\n",
    "# df_pp.item_id_mapping.to_parquet(\"communities/dariah/items_mapping.parquet\", index=False)\n",
    "# df_pp.user_id_mapping.to_parquet(\"communities/dariah/users_mapping.parquet\", index=False)\n",
    "\n",
    "# df_pp.item_id_mapping.to_parquet(\"communities/digital-humanities/items_mapping.parquet\", index=False)\n",
    "# df_pp.user_id_mapping.to_parquet(\"communities/digital-humanities/users_mapping.parquet\", index=False)\n",
    "\n",
    "df_pp.item_id_mapping.to_parquet(\"communities/transport-research/items_mapping.parquet\", index=False)\n",
    "df_pp.user_id_mapping.to_parquet(\"communities/transport-research/users_mapping.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sparsity after filtering\n",
    "sparsity = 1 - im.density\n",
    "\n",
    "# calculate user interaction and item popularity ranges\n",
    "user_interactions = im.binary_values.sum(axis=1)\n",
    "item_popularities = im.binary_values.sum(axis=0)\n",
    "print(f\"User interaction ranges from {user_interactions.min()} to {user_interactions.max()}. Item popularity ranges from {item_popularities.min()} to {item_popularities.max()}.\")\n",
    "\n",
    "# table stats\n",
    "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
    "statTable1.add_row([\"Community\", str(im.num_active_users), str(im.num_active_items), str(im.num_interactions), str(round(sparsity*100,2))])\n",
    "print(statTable1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scenario\n",
    "scenario = WeakGeneralization(validation=True, seed=1452)\n",
    "scenario.split(im)\n",
    "\n",
    "# define time threshold\n",
    "SECONDS = 12*3600\n",
    "\n",
    "# define number of evaluations\n",
    "EVALUATIONS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimisation's details for baselines\n",
    "optimisation_info_ease = HyperoptInfo(\n",
    "    {\n",
    "        \"l2\": hp.loguniform(\"l2\", np.log(1e0), np.log(1e4))\n",
    "    },\n",
    "    timeout = SECONDS,\n",
    "    max_evals = EVALUATIONS,\n",
    ")\n",
    "\n",
    "ALGORITHM_REGISTRY.register(myEASE.__name__, myEASE)\n",
    "\n",
    "# start pipeline\n",
    "pb = PipelineBuilder()\n",
    "pb.set_data_from_scenario(scenario)\n",
    "pb.add_algorithm(\"myEASE\", optimisation_info=optimisation_info_ease, params={\"method\": \"item\"})\n",
    "pb.set_optimisation_metric(\"NDCGK\", 10)\n",
    "pb.add_metric(\"NDCGK\", [10, 20])\n",
    "pb.add_metric(\"RecallK\", [10, 20])\n",
    "pb.add_metric(\"CoverageK\", [10, 20])\n",
    "\n",
    "pipe = pb.build()\n",
    "pipe.run()\n",
    "\n",
    "# save optimal parameters\n",
    "results = pipe.optimisation_results\n",
    "\n",
    "# myEASE\n",
    "myEASE_rows = results[results[\"algorithm\"] == \"myEASE\"]\n",
    "opt_myEASE_row = myEASE_rows.loc[myEASE_rows[\"NDCGK_\" + str(10)].idxmax()]\n",
    "ease_params = {\"l2\": opt_myEASE_row[\"params\"][\"l2\"]}\n",
    "\n",
    "# define model with optimal parameters\n",
    "model = myEASE(ease_params[\"l2\"],method=\"item\")\n",
    "\n",
    "# train model\n",
    "model.fit(scenario.full_training_data)\n",
    "\n",
    "# save model\n",
    "# pickle.dump(model, open(f\"communities/zbmath/ease.pkl\", \"wb\"))\n",
    "# pickle.dump(model, open(f\"communities/dariah/ease.pkl\", \"wb\"))\n",
    "# pickle.dump(model, open(f\"communities/digital-humanities/ease.pkl\", \"wb\"))\n",
    "pickle.dump(model, open(f\"communities/transport-research/ease.pkl\", \"wb\"))\n",
    "\n",
    "# # save results in test set\n",
    "pipe.save_metrics()\n",
    "\n",
    "# print results in test set\n",
    "pipe.get_metrics(short=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
