{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized recommendations to authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for training the community recommendation engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from recpack.matrix import InteractionMatrix\n",
    "from recpack.preprocessing.preprocessors import DataFramePreprocessor\n",
    "from recpack.preprocessing.filters import Deduplicate, MinItemsPerUser, NMostPopular\n",
    "from recpack.pipelines import PipelineBuilder, HyperoptInfo\n",
    "from recpack.pipelines.registries import ALGORITHM_REGISTRY\n",
    "from recpack.scenarios import WeakGeneralization\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "from src.recommenders.ease import myEASE\n",
    "from src.helpers.db_interactions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load the .env file\n",
    "\n",
    "# Fetch environment variables based on .env file structure\n",
    "db_host = os.getenv('HOST')\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_pass = os.getenv('PASSWORD')\n",
    "db_port = os.getenv('PORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of available communities\n",
    "communities = [\n",
    "    \"zbMATH\",\n",
    "    \"Transport Research\", \n",
    "    \"Digital Humanities and Cultural Heritage\", \n",
    "    \"Energy Research\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect data from DB to train recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    db_name = \"zbmath\" if community == \"zbMATH\" else \"fc4eosc\"\n",
    "    df = get_interactions_by_community(db_name, db_host, db_user, db_pass, db_port, community)\n",
    "    df_pp = DataFramePreprocessor(\"result_id\", \"author_id\")  # define preprocessor\n",
    "\n",
    "    pop_limit = min(df[\"result_id\"].nunique(), int(5e3)) # conditionally set the limit for NMostPopular filter\n",
    "    \n",
    "    # Define filters\n",
    "    deduplicate = Deduplicate(\"result_id\", \"author_id\")\n",
    "    n_most_popular_filter = NMostPopular(pop_limit, \"result_id\")\n",
    "    min_items_per_user_filter = MinItemsPerUser(10, \"result_id\", \"author_id\")\n",
    "\n",
    "    # Apply filters\n",
    "    df_pp.add_filter(deduplicate)\n",
    "    df_pp.add_filter(n_most_popular_filter)\n",
    "    df_pp.add_filter(min_items_per_user_filter) \n",
    "    \n",
    "    # Create interaction matrix object\n",
    "    im = df_pp.process(df)\n",
    "    \n",
    "    # Create the directory structure if it doesn't exist\n",
    "    directory = f\"communities/{community.replace(' ', '-').lower()}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save the InteractionMatrix object\n",
    "    im.save(f\"{directory}/im\")\n",
    "\n",
    "    # Save the InteractionMatrix in CSR format\n",
    "    save_npz(f\"{directory}/im_csr.npz\", im.values)\n",
    "\n",
    "    users_tuples = [(row[\"uid\"], row[\"author_id\"], community) for _, row in df_pp.user_id_mapping.iterrows()]\n",
    "    items_tuples = [\n",
    "        (int(row[\"iid\"]) if isinstance(row[\"iid\"], np.int64) else row[\"iid\"], \n",
    "         int(row[\"result_id\"]) if isinstance(row[\"result_id\"], np.int64) else row[\"result_id\"], \n",
    "         community) \n",
    "        for _, row in df_pp.item_id_mapping.iterrows()\n",
    "    ]\n",
    "    write_users_mappings(db_name, db_host, db_user, db_pass, db_port, users_tuples)\n",
    "    write_items_mappings(db_name, db_host, db_user, db_pass, db_port, items_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute interaction statistics for a particular community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = InteractionMatrix.load(\"communities/energy-research/im\")\n",
    "\n",
    "# compute sparsity after filtering\n",
    "sparsity = 1 - im.density\n",
    "\n",
    "# table stats\n",
    "statTable1 = PrettyTable([\"data set\",\"|U|\",\"|I|\",\"int(I)\",\"sparsity\"])\n",
    "statTable1.add_row([\"Community\", str(im.num_active_users), str(im.num_active_items), str(im.num_interactions), str(round(sparsity*100,2))])\n",
    "print(statTable1)\n",
    "\n",
    "# compute user popularity (row-wise sum)\n",
    "user_popularity = np.array(im.binary_values.sum(axis=1)).squeeze()\n",
    "print(\"User Popularity - Min:\", user_popularity.min(), \", Max:\", user_popularity.max())\n",
    "\n",
    "# compute item popularity (column-wise sum)\n",
    "item_popularity = np.array(im.binary_values.sum(axis=0)).squeeze()\n",
    "print(\"Item Popularity - Min:\", item_popularity.min(), \", Max:\", item_popularity.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM_REGISTRY.register(myEASE.__name__, myEASE) # registration if not already registered\n",
    "\n",
    "# Define time threshold and number of evaluations\n",
    "SECONDS = 12*3600; EVALUATIONS = 50\n",
    "\n",
    "# Define recommendation list sizes for metrics\n",
    "K = [10, 20, 50]\n",
    "\n",
    "for community in communities:\n",
    "    im = InteractionMatrix.load(f\"communities/{community.replace(' ', '-').lower()}/im\")\n",
    "\n",
    "    # Define evaluation scenario\n",
    "    scenario = WeakGeneralization(validation=True, seed=1452)\n",
    "    scenario.split(im)\n",
    "\n",
    "    # Set optimisation details\n",
    "    optimisation_info_ease = HyperoptInfo(\n",
    "        {\"l2\": hp.loguniform(\"l2\", np.log(1e0), np.log(1e4))},\n",
    "        timeout = SECONDS,\n",
    "        max_evals = EVALUATIONS,\n",
    "    )\n",
    "\n",
    "    # Start pipeline for fine-tuning\n",
    "    pb = PipelineBuilder(folder_name=f\"{community.replace(' ', '-').lower()}-results\")\n",
    "    pb.set_data_from_scenario(scenario)\n",
    "    pb.add_algorithm(\"myEASE\", optimisation_info=optimisation_info_ease, params={\"method\": \"item\"})\n",
    "    pb.set_optimisation_metric(\"NDCGK\", 10)\n",
    "    pb.add_metric(\"NDCGK\", K)\n",
    "    pb.add_metric(\"RecallK\", K)\n",
    "    pb.add_metric(\"CoverageK\", K)\n",
    "\n",
    "    pipe = pb.build()\n",
    "    pipe.run()\n",
    "\n",
    "    # Save optimal parameters\n",
    "    results = pipe.optimisation_results\n",
    "    myEASE_rows = results[results[\"algorithm\"] == \"myEASE\"]\n",
    "    opt_myEASE_row = myEASE_rows.loc[myEASE_rows[\"NDCGK_\" + str(10)].idxmax()]\n",
    "    ease_params = {\"l2\": opt_myEASE_row[\"params\"][\"l2\"]}\n",
    "\n",
    "    # Define and train model with optimal parameters\n",
    "    model = myEASE(ease_params[\"l2\"], method=\"item\")\n",
    "    model.fit(scenario.full_training_data)\n",
    "\n",
    "    # Save model\n",
    "    pickle.dump(model, open(f\"communities/{community.replace(' ', '-').lower()}/ease.pkl\", \"wb\"))\n",
    "\n",
    "    # Save and print results in test set\n",
    "    pipe.save_metrics()\n",
    "    print(f\"Results for {community}:\")\n",
    "    pipe.get_metrics(short=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
